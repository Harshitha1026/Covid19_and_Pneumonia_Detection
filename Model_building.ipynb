{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the paths\n",
    "data_dir_list = os.listdir('dataset')\n",
    "print(data_dir_list)\n",
    "\n",
    "path, dirs, files = next(os.walk(\"dataset\"))\n",
    "file_count = len(files)\n",
    "print(path, dirs, files, file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new base directory\n",
    "#original_dataset_dir = 'dataset'\n",
    "base_dir = 'data/'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two folders (train and test)\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "#Under train folder create 3 folders \n",
    "# (covid, pneumonia, normal )\n",
    "\n",
    "train_covid_dir = os.path.join(train_dir, 'covid')\n",
    "os.mkdir(train_covid_dir)\n",
    "\n",
    "train_pneumonia_dir = os.path.join(train_dir, 'pneumonia')\n",
    "os.mkdir(train_pneumonia_dir)\n",
    "\n",
    "train_normal_dir = os.path.join(train_dir, 'normal')\n",
    "os.mkdir(train_normal_dir)\n",
    "\n",
    "#Under test folder create 3 folders \n",
    "# (covid, pneumonia, normal )\n",
    "\n",
    "test_covid_dir = os.path.join(test_dir, 'covid')\n",
    "os.mkdir(test_covid_dir)\n",
    "\n",
    "test_pneumonia_dir = os.path.join(test_dir, 'pneumonia')\n",
    "os.mkdir(test_pneumonia_dir)\n",
    "\n",
    "test_normal_dir = os.path.join(test_dir, 'normal')\n",
    "os.mkdir(test_normal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    test_set = shuffled_set[training_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in test_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the path of original dataset \n",
    "COVID_SOURCE_DIR = 'dataset/COVID/'\n",
    "TRAINING_COVID_DIR = 'data/train/covid/'\n",
    "TEST_COVID_DIR = 'data/test/covid/'\n",
    "\n",
    "PNEU_SOURCE_DIR = 'dataset/PNEUMONIA/'\n",
    "TRAINING_PNEU_DIR = 'data/train/pneumonia/'\n",
    "TEST_PNEU_DIR = 'data/test/pneumonia/'\n",
    "\n",
    "NORMAL_SOURCE_DIR = 'dataset/NORMAL/'\n",
    "TRAINING_NORMAL_DIR = 'data/train/normal/'\n",
    "NORMAL_NORMAL_DIR = 'data/test/normal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset calling\n",
    "split_size = .75\n",
    "\n",
    "split_data(COVID_SOURCE_DIR, TRAINING_COVID_DIR, TEST_COVID_DIR, split_size)\n",
    "split_data(PNEU_SOURCE_DIR, TRAINING_PNEU_DIR, TEST_PNEU_DIR, split_size)\n",
    "split_data(NORMAL_SOURCE_DIR, TRAINING_NORMAL_DIR, NORMAL_NORMAL_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of training dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "import pathlib\n",
    "\n",
    "image_folder = ['covid', 'pneumonia', 'normal']\n",
    "nimgs = {}\n",
    "for i in image_folder:\n",
    "    nimages = len(os.listdir('data/train/'+i+'/'))\n",
    "    nimgs[i]=nimages\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
    "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
    "plt.title('Distribution of different classes in Training Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding no of training dataset of each class\n",
    "for i in ['covid', 'pneumonia', 'normal']:\n",
    "    print('Training {} images are: '.format(i)+str(len(os.listdir('data/train/'+i+'/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of testing dataset\n",
    "\n",
    "image_folder = ['covid', 'pneumonia', 'normal']\n",
    "nimgs = {}\n",
    "for i in image_folder:\n",
    "    nimages = len(os.listdir('data/test/'+i+'/'))\n",
    "    nimgs[i]=nimages\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
    "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
    "plt.title('Distribution of different classes in Testing Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding no of training dataset of each class\n",
    "\n",
    "for i in ['covid', 'pneumonia', 'normal']:\n",
    "    print('Valid {} images are: '.format(i)+str(len(os.listdir('data/test/'+i+'/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization\n",
    "img_width=224; img_height=224\n",
    "batch_size=64  #defines the number of samples that will be propagated through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "TRAINING_DIR = 'data/train/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.4,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                  shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(img_height, img_width)\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-50 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "from tensorflow.keras.layers import Flatten , Dense, Dropout , MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "res= ResNet50(include_top=False,\n",
    "                   input_shape=(224,224,3),\n",
    "                   pooling=max,classes=3,\n",
    "                   weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in res.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "print(len(res.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.add(res)\n",
    "resnet_model.add(Flatten())\n",
    "#resnet_model.add(Dense(512,activation='relu'))\n",
    "resnet_model.add(Dense(256,activation='relu'))\n",
    "resnet_model.add(Dense(3,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor= \"val_accuracy\" , min_delta= 0.01, patience= 3, verbose=1)\n",
    "mc = ModelCheckpoint(filepath=\"bestmodel.h5\", monitor=\"val_accuracy\", verbose=1, save_best_only= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = resnet_model.fit(train_generator, steps_per_epoch= 35, epochs= 15, validation_data= test_generator , validation_steps= 32, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG-16 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten , Dense, Dropout , MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16( input_shape=(299,299,3), include_top= False) # include_top will consider the new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:           # Dont Train the parameters again \n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "x = Dense(units=3 , activation='softmax', name = 'predictions' )(x)\n",
    "\n",
    "model = Model(vgg.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor= \"accuracy\" , min_delta= 0.01, patience= 3, verbose=1)\n",
    "mc = ModelCheckpoint(filepath=\"bestmodel.h5\", monitor=\"accuracy\", verbose=1, save_best_only= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_generator, steps_per_epoch= 10, epochs= 10, validation_data= test_generator , validation_steps= 16, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model = load_model(\"bestmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "VALID_DIR = 'data/test/'\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALID_DIR,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(img_height, img_width))\n",
    "test_steps_per_epoch = numpy.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "predictions = model.predict(validation_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = numpy.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont change\n",
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(img_height, img_width))\n",
    "\n",
    "print(\"Accuracy : \", str(model.evaluate(test_generator)[1]*100))\n",
    "\n",
    "#print(\"Accuracy : \", str(model.evaluate(validation_generator)[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(true_classes)):\n",
    "    print(true_classes[i], predicted_classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Classification Report')\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "\n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion Matrix')\n",
    "d = confusion_matrix(true_classes, predicted_classes)\n",
    "print(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(cf_matrix)\n",
    "\n",
    "categories = ['covid', 'normal','pneumonia']\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "labels = ['covid', 'normal','pneumonia']\n",
    "#sns.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    "\n",
    "plt.savefig(\"cf.png\", bbox_inches='tight', dpi=300)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=hist.history['accuracy']\n",
    "val_acc=hist.history['val_accuracy']\n",
    "loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "epochs=range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig2 = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('bestmodel.h5')\n",
    "\n",
    "class_type = {0:'covid', 1:'normal', 2:'pneumonia'}\n",
    "\n",
    "def predict_(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image,(224,224))\n",
    "    image = preprocess_input(image)\n",
    "    image = image.reshape(1,224,224,3)\n",
    "    preds = model.predict(image)\n",
    "    preds = np.argmax(preds,axis=1)[0]\n",
    "    if preds==0:\n",
    "        print(\"Predicted Label:Covid\")\n",
    "    elif preds==2:\n",
    "        print(\"Predicted Label: Pneumonia\")\n",
    "    else:\n",
    "        print(\"Predicted Label: Normal\")\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='Covid.jpg'\n",
    "predict_(path)\n",
    "\n",
    "path='Normal.jpeg'\n",
    "predict_(path)\n",
    "\n",
    "path='Pneumonia.jpg'\n",
    "predict_(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.20\n",
    "#fig = plt.subplots(figsize =(12, 8))\n",
    "fig = plt.subplots(figsize =(12, 5))\n",
    "\n",
    "# set height of bar\n",
    "Training_Accuracy= [95.85, 93.93, 93.45, 93.54]\n",
    "Teasting_Accuracy = [93.26, 92.78, 89.42, 90.86]\n",
    "Validation_Accuracy = [94.14, 93.55, 91.79, 89.94]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Training_Accuracy))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(br1, Training_Accuracy, color ='r', width = barWidth,\n",
    "\t\tedgecolor ='grey', label ='Training')\n",
    "plt.bar(br2, Teasting_Accuracy, color ='g', width = barWidth,\n",
    "\t\tedgecolor ='grey', label ='Teasting')\n",
    "plt.bar(br3, Validation_Accuracy, color ='b', width = barWidth,\n",
    "\t\tedgecolor ='grey', label ='Validation')\n",
    "\n",
    "# Adding Xticks\n",
    "plt.xlabel('Architecture', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Training_Accuracy))],\n",
    "\t\t['ResNet-50', 'ResNet-101', 'VGG-16', 'VGG-19'])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
